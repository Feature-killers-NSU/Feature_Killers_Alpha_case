{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7042404,"sourceType":"datasetVersion","datasetId":4051990}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\npd.set_option('display.max_rows', 500)\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\nfrom tqdm import tqdm\nfrom sklearn.metrics import roc_auc_score\nfrom collections import defaultdict\n\nfrom scipy.cluster import hierarchy\nfrom scipy.spatial.distance import squareform\n\nfrom sklearn.compose import make_column_selector, make_column_transformer\nfrom sklearn.pipeline import make_pipeline\n\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.base import TransformerMixin, BaseEstimator\n\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nimport optuna","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-30T13:41:02.102002Z","iopub.execute_input":"2023-11-30T13:41:02.102598Z","iopub.status.idle":"2023-11-30T13:41:02.111868Z","shell.execute_reply.started":"2023-11-30T13:41:02.102562Z","shell.execute_reply":"2023-11-30T13:41:02.110714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_parquet('/kaggle/input/alpha-contest/train.parquet').set_index('id')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:48.140101Z","iopub.execute_input":"2023-11-30T13:21:48.140490Z","iopub.status.idle":"2023-11-30T13:21:48.902067Z","shell.execute_reply.started":"2023-11-30T13:21:48.140437Z","shell.execute_reply":"2023-11-30T13:21:48.901070Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data cleaning","metadata":{}},{"cell_type":"markdown","source":"## Data is noised!","metadata":{}},{"cell_type":"markdown","source":"In this contest data is anonymized by appling random noise. During the EDA process we understood that for some variable the noise was gaussian. As for clear example, we can take discrete variable 'cnt_days_deb_e_oper_1m'.","metadata":{}},{"cell_type":"code","source":"feature = train_df['cnt_days_deb_e_oper_1m']\nsns.histplot(feature[(feature > -1) & (feature < 6)], binwidth=0.01)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:48.903310Z","iopub.execute_input":"2023-11-30T13:21:48.903618Z","iopub.status.idle":"2023-11-30T13:21:50.176314Z","shell.execute_reply.started":"2023-11-30T13:21:48.903592Z","shell.execute_reply":"2023-11-30T13:21:50.174882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thus, our feature is a mixture of gaussian distributions with mean near the true value of this variable (discrete values: 0, 1, 2, 3 ...). But why is it so important? Quick inspection of features ranges showed us that there are outliers that can be a result of technical mistake (like more than 31 days in month). \n\n- Thus our filtering boundaries should be less strict to take into account noise. \n- In addition to this, our findings means that number of unique values for each feature should be inspected manually, because near-const feature after noising, can suddenly have a lot of unique values.","metadata":{}},{"cell_type":"markdown","source":"## Examples of Negative and Large Values","metadata":{}},{"cell_type":"code","source":"(train_df['rko_start_months'] < 0).sum()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.177693Z","iopub.execute_input":"2023-11-30T13:21:50.178068Z","iopub.status.idle":"2023-11-30T13:21:50.186511Z","shell.execute_reply.started":"2023-11-30T13:21:50.178036Z","shell.execute_reply":"2023-11-30T13:21:50.185363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(train_df['cnt_days_cred_h_oper_3m'] > 31).sum()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.190285Z","iopub.execute_input":"2023-11-30T13:21:50.191090Z","iopub.status.idle":"2023-11-30T13:21:50.200925Z","shell.execute_reply.started":"2023-11-30T13:21:50.191047Z","shell.execute_reply":"2023-11-30T13:21:50.199759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Boundaries for each numeric feature will be discussed in the next section! Technical outliers will be mapped to NaN where.","metadata":{}},{"cell_type":"markdown","source":"# Numeric Features","metadata":{}},{"cell_type":"markdown","source":"## NaN check","metadata":{}},{"cell_type":"code","source":"(train_df.select_dtypes(include='number').isna()).sum()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.202729Z","iopub.execute_input":"2023-11-30T13:21:50.203418Z","iopub.status.idle":"2023-11-30T13:21:50.628548Z","shell.execute_reply.started":"2023-11-30T13:21:50.203379Z","shell.execute_reply":"2023-11-30T13:21:50.627366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2 interesting things drew our eyes:\n\n- There are feature with a half of NaN values, this features might be dropped or replaced with NaN indicator column\n- Some of features (with cnt in their name) have suspiciously equal number of missing values - the assumption is that it the same cluster of people.","metadata":{}},{"cell_type":"markdown","source":"## Same number of nans","metadata":{}},{"cell_type":"code","source":"cnt_columns = [col for col in train_df.columns if 'cnt' in col]","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.629786Z","iopub.execute_input":"2023-11-30T13:21:50.630404Z","iopub.status.idle":"2023-11-30T13:21:50.635109Z","shell.execute_reply.started":"2023-11-30T13:21:50.630373Z","shell.execute_reply":"2023-11-30T13:21:50.634102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nan_people = train_df[train_df[cnt_columns].isna().any(axis=1)]\nnan_people.isna().sum().loc[cnt_columns]","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.636586Z","iopub.execute_input":"2023-11-30T13:21:50.637138Z","iopub.status.idle":"2023-11-30T13:21:50.722705Z","shell.execute_reply.started":"2023-11-30T13:21:50.637107Z","shell.execute_reply":"2023-11-30T13:21:50.721548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nan_people.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.724302Z","iopub.execute_input":"2023-11-30T13:21:50.724647Z","iopub.status.idle":"2023-11-30T13:21:50.731321Z","shell.execute_reply.started":"2023-11-30T13:21:50.724611Z","shell.execute_reply":"2023-11-30T13:21:50.730120Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 6521 entries that have NaNs for all cnt features. In addition to this, these people have additional columns with NaN values and strange operation sum values, for example 'sum_cred_f_oper_1m. Due to noise factor, round values of sum features will be showed to see the approximate number of unique values for each column.That's why we decided to drop these people.","metadata":{}},{"cell_type":"code","source":"nan_people['sum_deb_g_oper_1m'].round().value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.732847Z","iopub.execute_input":"2023-11-30T13:21:50.734072Z","iopub.status.idle":"2023-11-30T13:21:50.744669Z","shell.execute_reply.started":"2023-11-30T13:21:50.734031Z","shell.execute_reply":"2023-11-30T13:21:50.743459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nan_people['sum_cred_g_oper_1m'].round().value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.748008Z","iopub.execute_input":"2023-11-30T13:21:50.748419Z","iopub.status.idle":"2023-11-30T13:21:50.760810Z","shell.execute_reply.started":"2023-11-30T13:21:50.748391Z","shell.execute_reply":"2023-11-30T13:21:50.759725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nan_people['sum_cred_e_oper_1m'].round().value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.762116Z","iopub.execute_input":"2023-11-30T13:21:50.763105Z","iopub.status.idle":"2023-11-30T13:21:50.774767Z","shell.execute_reply.started":"2023-11-30T13:21:50.763072Z","shell.execute_reply":"2023-11-30T13:21:50.773699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nan_people['sum_a_oper_1m'].round().value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.776219Z","iopub.execute_input":"2023-11-30T13:21:50.776991Z","iopub.status.idle":"2023-11-30T13:21:50.787063Z","shell.execute_reply.started":"2023-11-30T13:21:50.776959Z","shell.execute_reply":"2023-11-30T13:21:50.785805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nan_people['sum_b_oper_1m'].round().value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.793373Z","iopub.execute_input":"2023-11-30T13:21:50.793736Z","iopub.status.idle":"2023-11-30T13:21:50.802172Z","shell.execute_reply.started":"2023-11-30T13:21:50.793708Z","shell.execute_reply":"2023-11-30T13:21:50.801102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Number of days for certain operation","metadata":{}},{"cell_type":"markdown","source":"There is a subset of feature that indicate number of days in a given period, when certain operation has occured. For example 'cnt_days_cred_g_oper_1m' or 'cnt_days_deb_f_oper_3m'.  It's obvious that these values are bounded by 0 and the length of a period in days. There are 2 periods in the data, thus we will have 31 and 93 as upper bounds. \n\nBut as we discussed earlier they must be corrected according to noise process. We suggest -2 for lower bound and 35, 100 for upper bounds.","metadata":{}},{"cell_type":"code","source":"cnt_days_features = [col for col in train_df.columns if 'cnt_days' in col]\ncnt_days_features","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.803376Z","iopub.execute_input":"2023-11-30T13:21:50.804266Z","iopub.status.idle":"2023-11-30T13:21:50.814984Z","shell.execute_reply.started":"2023-11-30T13:21:50.804223Z","shell.execute_reply":"2023-11-30T13:21:50.814137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 1 month period","metadata":{}},{"cell_type":"code","source":"cnt_days_one_features = [col for col in cnt_days_features if '1m' in col]\ncnt_days_one_df = train_df[cnt_days_one_features]","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.816441Z","iopub.execute_input":"2023-11-30T13:21:50.816817Z","iopub.status.idle":"2023-11-30T13:21:50.830957Z","shell.execute_reply.started":"2023-11-30T13:21:50.816788Z","shell.execute_reply":"2023-11-30T13:21:50.829960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(cnt_days_one_df < -2).sum()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.832299Z","iopub.execute_input":"2023-11-30T13:21:50.832590Z","iopub.status.idle":"2023-11-30T13:21:50.854755Z","shell.execute_reply.started":"2023-11-30T13:21:50.832566Z","shell.execute_reply":"2023-11-30T13:21:50.853720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(cnt_days_one_df > 35).sum()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.855700Z","iopub.execute_input":"2023-11-30T13:21:50.856748Z","iopub.status.idle":"2023-11-30T13:21:50.868610Z","shell.execute_reply.started":"2023-11-30T13:21:50.856715Z","shell.execute_reply":"2023-11-30T13:21:50.867550Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see we can have both negative and big outliers. Let's take an example of one column.","metadata":{}},{"cell_type":"code","source":"cnt_days_one_df.loc[cnt_days_one_df['cnt_days_deb_e_oper_1m'] > 35, 'cnt_days_deb_e_oper_1m']","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.869819Z","iopub.execute_input":"2023-11-30T13:21:50.870675Z","iopub.status.idle":"2023-11-30T13:21:50.880666Z","shell.execute_reply.started":"2023-11-30T13:21:50.870642Z","shell.execute_reply":"2023-11-30T13:21:50.879780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are tremendous values. As we can see our boundaries do great job dealing with unreal outliers.","metadata":{}},{"cell_type":"code","source":"def clear_columns(df, lower, upper):\n    \n    for col in df.columns:\n        df.loc[(df[col] < -2) | (df[col] > 35), col] = np.NaN\n        \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.881752Z","iopub.execute_input":"2023-11-30T13:21:50.882353Z","iopub.status.idle":"2023-11-30T13:21:50.888947Z","shell.execute_reply.started":"2023-11-30T13:21:50.882324Z","shell.execute_reply":"2023-11-30T13:21:50.887875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt_days_one_df = clear_columns(cnt_days_one_df, -2, 35)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.890511Z","iopub.execute_input":"2023-11-30T13:21:50.891136Z","iopub.status.idle":"2023-11-30T13:21:50.919880Z","shell.execute_reply.started":"2023-11-30T13:21:50.891099Z","shell.execute_reply":"2023-11-30T13:21:50.918844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_hists_clipped(df, binwidth):\n    n_charts = df.shape[1]\n               \n    fig, axarr = plt.subplots(nrows = n_charts, figsize=(8, n_charts*4))\n\n    for i in range(n_charts):\n\n        feature = df.iloc[:, i]\n        \n        if type(axarr) == np.ndarray:\n            cur_ax = axarr[i]\n        else:\n            cur_ax = axarr\n            \n        sns.histplot(feature, ax=cur_ax, binwidth=binwidth)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.921266Z","iopub.execute_input":"2023-11-30T13:21:50.921656Z","iopub.status.idle":"2023-11-30T13:21:50.929322Z","shell.execute_reply.started":"2023-11-30T13:21:50.921619Z","shell.execute_reply":"2023-11-30T13:21:50.928137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_hists_clipped(cnt_days_one_df, 0.1)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:21:50.930994Z","iopub.execute_input":"2023-11-30T13:21:50.931553Z","iopub.status.idle":"2023-11-30T13:22:00.018767Z","shell.execute_reply.started":"2023-11-30T13:21:50.931519Z","shell.execute_reply":"2023-11-30T13:22:00.017662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt_days_one_df.std()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:00.020398Z","iopub.execute_input":"2023-11-30T13:22:00.021110Z","iopub.status.idle":"2023-11-30T13:22:00.067198Z","shell.execute_reply.started":"2023-11-30T13:22:00.021065Z","shell.execute_reply":"2023-11-30T13:22:00.066196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- All distribution after removing outliers look like an expontial distribution.\n- It looks like cnt_days_cred_f_oper_1m' before appling noise could take small number of values (like 0, 1, 2), we can consider to drop these feature, because our model can start to learn something from the noise of that variable, while in reality it almost always equal to 0. It's low variance proves out theory.\n- Maybe Binarization of continuous variables is required for removing undesireble noise. For the number of bins we could take the original number of unique values before applying noise. As for the method, I think 1-d KMeans clustering would work, because centroid will be chosen at the chart picks","metadata":{}},{"cell_type":"markdown","source":"## 3 month period","metadata":{}},{"cell_type":"markdown","source":"Let's repeat all but with longer period","metadata":{}},{"cell_type":"code","source":"cnt_days_three_features = [col for col in cnt_days_features if '3m' in col]\ncnt_days_three_df = train_df[cnt_days_three_features]","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:00.068718Z","iopub.execute_input":"2023-11-30T13:22:00.069450Z","iopub.status.idle":"2023-11-30T13:22:00.081250Z","shell.execute_reply.started":"2023-11-30T13:22:00.069409Z","shell.execute_reply":"2023-11-30T13:22:00.079781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(cnt_days_three_df < -2).sum()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:00.082587Z","iopub.execute_input":"2023-11-30T13:22:00.082958Z","iopub.status.idle":"2023-11-30T13:22:00.102258Z","shell.execute_reply.started":"2023-11-30T13:22:00.082929Z","shell.execute_reply":"2023-11-30T13:22:00.100810Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(cnt_days_three_df > 100).sum()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:00.103631Z","iopub.execute_input":"2023-11-30T13:22:00.104001Z","iopub.status.idle":"2023-11-30T13:22:00.117687Z","shell.execute_reply.started":"2023-11-30T13:22:00.103971Z","shell.execute_reply":"2023-11-30T13:22:00.116218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt_days_three_df = clear_columns(cnt_days_three_df, -2, 100)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:00.119551Z","iopub.execute_input":"2023-11-30T13:22:00.120014Z","iopub.status.idle":"2023-11-30T13:22:00.159125Z","shell.execute_reply.started":"2023-11-30T13:22:00.119973Z","shell.execute_reply":"2023-11-30T13:22:00.157832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_hists_clipped(cnt_days_three_df, 1)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:00.161193Z","iopub.execute_input":"2023-11-30T13:22:00.161642Z","iopub.status.idle":"2023-11-30T13:22:04.649462Z","shell.execute_reply.started":"2023-11-30T13:22:00.161601Z","shell.execute_reply":"2023-11-30T13:22:04.648345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt_days_three_df.std()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:04.650868Z","iopub.execute_input":"2023-11-30T13:22:04.651296Z","iopub.status.idle":"2023-11-30T13:22:04.712457Z","shell.execute_reply.started":"2023-11-30T13:22:04.651261Z","shell.execute_reply":"2023-11-30T13:22:04.711392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Same insights - exponential distributions for all features, low-variance cnt_days_cred_f_oper_3m, usage of binning.","metadata":{}},{"cell_type":"markdown","source":"## Features - ogrn_days_end_month and ogrn_days_end_quarter","metadata":{}},{"cell_type":"markdown","source":"Same logic can be applied for these 2 features. They still bounded by 0, and upper bounds are month (31) and quarter (93)","metadata":{}},{"cell_type":"code","source":"ogrn_days_month, ogrn_days_quarter = train_df['ogrn_days_end_month'], train_df['ogrn_days_end_quarter']","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:04.714112Z","iopub.execute_input":"2023-11-30T13:22:04.714921Z","iopub.status.idle":"2023-11-30T13:22:04.722515Z","shell.execute_reply.started":"2023-11-30T13:22:04.714878Z","shell.execute_reply":"2023-11-30T13:22:04.721349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(ogrn_days_month < -2).sum()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:04.723458Z","iopub.execute_input":"2023-11-30T13:22:04.723780Z","iopub.status.idle":"2023-11-30T13:22:04.735900Z","shell.execute_reply.started":"2023-11-30T13:22:04.723750Z","shell.execute_reply":"2023-11-30T13:22:04.734906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(ogrn_days_month > 35).sum()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:04.737651Z","iopub.execute_input":"2023-11-30T13:22:04.737965Z","iopub.status.idle":"2023-11-30T13:22:04.748578Z","shell.execute_reply.started":"2023-11-30T13:22:04.737938Z","shell.execute_reply":"2023-11-30T13:22:04.747430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(ogrn_days_month)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:04.749990Z","iopub.execute_input":"2023-11-30T13:22:04.750490Z","iopub.status.idle":"2023-11-30T13:22:06.736920Z","shell.execute_reply.started":"2023-11-30T13:22:04.750460Z","shell.execute_reply":"2023-11-30T13:22:06.736101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"ogrn_days_end_month needs removing technical outliers.","metadata":{}},{"cell_type":"code","source":"sns.histplot(ogrn_days_quarter)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:06.738118Z","iopub.execute_input":"2023-11-30T13:22:06.738635Z","iopub.status.idle":"2023-11-30T13:22:07.446050Z","shell.execute_reply.started":"2023-11-30T13:22:06.738607Z","shell.execute_reply":"2023-11-30T13:22:07.445248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This feature on the other hand doesn't any addtional preprocessing.","metadata":{}},{"cell_type":"code","source":"ogrn_days_month = clear_columns(ogrn_days_month.to_frame(), -2, 35)\nplot_hists_clipped(ogrn_days_month, 0.1)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:07.447257Z","iopub.execute_input":"2023-11-30T13:22:07.447738Z","iopub.status.idle":"2023-11-30T13:22:08.580375Z","shell.execute_reply.started":"2023-11-30T13:22:07.447710Z","shell.execute_reply":"2023-11-30T13:22:08.579579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As for their correlation to target, the first opinion was that these periodic features don't carry any information about behaviour pattern. In fact, box plots for these variable across target values prove it!","metadata":{}},{"cell_type":"code","source":"sns.boxplot(x=train_df['total_target'], y=train_df['ogrn_days_end_month'])","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:08.581577Z","iopub.execute_input":"2023-11-30T13:22:08.582057Z","iopub.status.idle":"2023-11-30T13:22:09.210520Z","shell.execute_reply.started":"2023-11-30T13:22:08.582030Z","shell.execute_reply":"2023-11-30T13:22:09.209339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## rko_start_month","metadata":{}},{"cell_type":"code","source":"sns.boxplot(x=train_df['total_target'], y=train_df['rko_start_months'])","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:09.212316Z","iopub.execute_input":"2023-11-30T13:22:09.212934Z","iopub.status.idle":"2023-11-30T13:22:09.622812Z","shell.execute_reply.started":"2023-11-30T13:22:09.212892Z","shell.execute_reply":"2023-11-30T13:22:09.621738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Alpha Bank was founded in 1990, so the upper bound will be 792 months (33 years * 12 months)","metadata":{}},{"cell_type":"code","source":"clipped_rko = train_df.loc[(train_df['rko_start_months'] > 0) & (train_df['rko_start_months'] < 792)]","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:09.624212Z","iopub.execute_input":"2023-11-30T13:22:09.624610Z","iopub.status.idle":"2023-11-30T13:22:09.760863Z","shell.execute_reply.started":"2023-11-30T13:22:09.624583Z","shell.execute_reply":"2023-11-30T13:22:09.759564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.boxplot(x=clipped_rko['total_target'], y=clipped_rko['rko_start_months'])","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:09.762645Z","iopub.execute_input":"2023-11-30T13:22:09.763052Z","iopub.status.idle":"2023-11-30T13:22:10.057938Z","shell.execute_reply.started":"2023-11-30T13:22:09.763018Z","shell.execute_reply":"2023-11-30T13:22:10.056619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Other numerical features","metadata":{}},{"cell_type":"markdown","source":"For these features only lower bound -2 will be used. As for upper bound we don't have any logic explanation, because of lack of domain knowledge, so we derive it from data. The reason to remove tremendous outliers lies in a problem of interpretability of our model. Let's take an examples.","metadata":{}},{"cell_type":"code","source":"def scatter_and_corr(df, column1, column2):\n    sns.scatterplot(x=df[column1], y=df[column2])\n    print(f\"Correlation = {df[[column1, column2]].corr().iloc[1,0]}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:10.068109Z","iopub.execute_input":"2023-11-30T13:22:10.068678Z","iopub.status.idle":"2023-11-30T13:22:10.075455Z","shell.execute_reply.started":"2023-11-30T13:22:10.068637Z","shell.execute_reply":"2023-11-30T13:22:10.074430Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter_and_corr(train_df,'cnt_deb_e_oper_1m', 'balance_amt_avg')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:10.076750Z","iopub.execute_input":"2023-11-30T13:22:10.077079Z","iopub.status.idle":"2023-11-30T13:22:11.697701Z","shell.execute_reply.started":"2023-11-30T13:22:10.077043Z","shell.execute_reply":"2023-11-30T13:22:11.696474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter_and_corr(train_df,'cnt_cred_e_oper_1m', 'balance_amt_max')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:11.699043Z","iopub.execute_input":"2023-11-30T13:22:11.699653Z","iopub.status.idle":"2023-11-30T13:22:13.294706Z","shell.execute_reply.started":"2023-11-30T13:22:11.699618Z","shell.execute_reply":"2023-11-30T13:22:13.293320Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter_and_corr(train_df,'sum_deb_e_oper_1m', 'balance_amt_min')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:13.296283Z","iopub.execute_input":"2023-11-30T13:22:13.296702Z","iopub.status.idle":"2023-11-30T13:22:14.934064Z","shell.execute_reply.started":"2023-11-30T13:22:13.296659Z","shell.execute_reply":"2023-11-30T13:22:14.933096Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In all three example we see a big and isolated outliers (that's very unnatural for continuos nature of our data). The logistic regression may struggle to interpolate these points. In addition to this issues, pearson correlation test gives biased numbers (after removing correlation may go lower and higher).","metadata":{}},{"cell_type":"code","source":"x = train_df[train_df['balance_amt_min'] < 100000000]\nscatter_and_corr(x, 'balance_amt_min', 'sum_deb_e_oper_1m')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:14.935436Z","iopub.execute_input":"2023-11-30T13:22:14.935767Z","iopub.status.idle":"2023-11-30T13:22:16.696092Z","shell.execute_reply.started":"2023-11-30T13:22:14.935739Z","shell.execute_reply":"2023-11-30T13:22:16.694946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As another examples are (balance_amt_avg and balance_amt_max); (balance_avg_days_avg and balance_amt_avg), these pairs should correlate, but in data there is no correlation!","metadata":{}},{"cell_type":"code","source":"scatter_and_corr(train_df, 'balance_amt_avg', 'balance_amt_max')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:16.697634Z","iopub.execute_input":"2023-11-30T13:22:16.697996Z","iopub.status.idle":"2023-11-30T13:22:18.324816Z","shell.execute_reply.started":"2023-11-30T13:22:16.697964Z","shell.execute_reply":"2023-11-30T13:22:18.323704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = train_df[(train_df['balance_amt_max'] < 100000000) & (train_df['balance_amt_avg'] < 100000000)]\nscatter_and_corr(x, 'balance_amt_max', 'balance_amt_avg')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:18.326448Z","iopub.execute_input":"2023-11-30T13:22:18.326767Z","iopub.status.idle":"2023-11-30T13:22:20.092218Z","shell.execute_reply.started":"2023-11-30T13:22:18.326741Z","shell.execute_reply":"2023-11-30T13:22:20.091005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scatter_and_corr(train_df, 'balance_amt_day_avg', 'balance_amt_avg')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:20.093700Z","iopub.execute_input":"2023-11-30T13:22:20.094041Z","iopub.status.idle":"2023-11-30T13:22:21.718728Z","shell.execute_reply.started":"2023-11-30T13:22:20.094012Z","shell.execute_reply":"2023-11-30T13:22:21.717251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = train_df[(train_df['balance_amt_avg'] < 1000000000) & (train_df['balance_amt_day_avg'] < 1000000000)]\nscatter_and_corr(x, 'balance_amt_avg', 'balance_amt_day_avg')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:21.720383Z","iopub.execute_input":"2023-11-30T13:22:21.720746Z","iopub.status.idle":"2023-11-30T13:22:23.472646Z","shell.execute_reply.started":"2023-11-30T13:22:21.720715Z","shell.execute_reply":"2023-11-30T13:22:23.471478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The justice** is restored!","metadata":{}},{"cell_type":"markdown","source":"That will be a problem on stage of removing correlated features for simpler interpretation of our models. Our team decided to find these points manually and replace them with NaNs. We will provide only the final results (upper bounds). Some of them may make sense like sum of operations being for 1 month being 1.000.000.000 roubles (which we think is impossible for russian companies)","metadata":{}},{"cell_type":"code","source":"upper_bounds = {\n    \n        'cnt_days_deb_e_oper_1m':35,\n        'cnt_days_cred_e_oper_1m':35,\n        'cnt_days_deb_f_oper_1m':35,\n        'cnt_days_cred_f_oper_1m':35,\n        'cnt_days_deb_g_oper_1m':35,\n        'cnt_days_cred_g_oper_1m':35,\n        'cnt_days_deb_h_oper_1m':35,\n        'cnt_days_cred_h_oper_1m':35,\n        \n        'cnt_days_deb_e_oper_3m':100,\n        'cnt_days_cred_e_oper_3m':100,\n        'cnt_days_deb_f_oper_3m':100,\n        'cnt_days_cred_f_oper_3m':100,\n        'cnt_days_deb_g_oper_3m':100,\n        'cnt_days_cred_g_oper_3m':100,\n        'cnt_days_deb_h_oper_3m':100,\n        'cnt_days_cred_h_oper_3m':100,\n    \n        'rko_start_months':792,\n        \n        'balance_amt_avg':1000000000,\n        'balance_amt_max':10000000000,\n        'balance_amt_min':1000000000,\n        'balance_amt_day_avg':1000000000,\n    \n        'ft_registration_date':20000,\n    \n        'sum_of_paym_2m':10000000000,\n        'sum_of_paym_6m':10000000000,\n    \n        'sum_a_oper_1m':10000000,\n        'cnt_a_oper_1m':2000,\n    \n        'sum_b_oper_1m':10000000000,\n        'cnt_b_oper_1m':100,\n    \n        'cnt_c_oper_1m':10000,\n        'sum_deb_d_oper_1m':1000000000,\n        \n        'sum_cred_d_oper_1m':1000000000,\n        'cnt_cred_d_oper_1m':1500,\n        'sum_deb_e_oper_1m':10000000000,\n        'cnt_deb_e_oper_1m':50000,\n        'sum_cred_e_oper_1m':10000000000,\n        'cnt_cred_e_oper_1m':10000,\n        'cnt_deb_f_oper_1m':10000,\n        'sum_cred_f_oper_1m':1000000000,\n        'cnt_cred_f_oper_1m':10000,\n        'cnt_deb_g_oper_1m':10000,\n        'sum_deb_h_oper_1m':10000000000,\n        'cnt_deb_h_oper_1m':10000,\n        'sum_cred_h_oper_1m':10000000000,\n        'cnt_cred_h_oper_1m':10000,\n        'sum_a_oper_3m':100000000,\n        'cnt_a_oper_3m':1000,\n        'sum_b_oper_3m':10000000000,\n        'cnt_b_oper_3m':1000,\n        'sum_c_oper_3m':100000000,\n        'cnt_c_oper_3m':10000,\n        'sum_deb_d_oper_3m':1000000000,\n        'cnt_deb_d_oper_3m':10000,\n        'cnt_cred_d_oper_3m':10000,\n        'cnt_deb_e_oper_3m':1000000,\n        'sum_cred_e_oper_3m':10000000000,\n        'cnt_cred_e_oper_3m':100000,\n        'sum_deb_f_oper_3m':1000000000,\n        'cnt_deb_f_oper_3m':100000,\n        'sum_cred_f_oper_3m':1000000000,\n        'cnt_deb_g_oper_3m':10000,\n        'sum_cred_g_oper_3m':10000000000,\n        'sum_deb_h_oper_3m':10000000000,\n        'sum_cred_h_oper_3m':10000000000,\n        \n    }","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:23.474318Z","iopub.execute_input":"2023-11-30T13:22:23.474916Z","iopub.status.idle":"2023-11-30T13:22:23.486878Z","shell.execute_reply.started":"2023-11-30T13:22:23.474875Z","shell.execute_reply":"2023-11-30T13:22:23.485669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final numeric features code","metadata":{}},{"cell_type":"code","source":"def clean_data(X):\n\n    object_columns = X.columns[X.dtypes == 'object']\n\n    cnt_days_one_columns = [col for col in X.columns if ('cnt_days' in col) & ('1m' in col)]\n    cnt_days_three_columns = [col for col in X.columns if ('cnt_days' in col) & ('3m' in col)]\n\n    for column in X.columns:\n        if column not in object_columns:\n            \n            outlier_filter = X[column] < -2\n\n            if column in upper_bounds.keys():\n                outlier_filter = outlier_filter | (X[column] > upper_bounds[column])       \n                                                  \n            X.loc[outlier_filter, column] = np.NaN\n\n    return X","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:23.488628Z","iopub.execute_input":"2023-11-30T13:22:23.489043Z","iopub.status.idle":"2023-11-30T13:22:23.504605Z","shell.execute_reply.started":"2023-11-30T13:22:23.489002Z","shell.execute_reply":"2023-11-30T13:22:23.503489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def drop_num_features(X):\n    # Drop Feature with bgi % of nan values\n    X = X.drop(columns=[col for col in X.columns if ('deals' in col) | ('founder' in col)])\n\n    # Drop irrelevant features\n    X = X.drop(columns=['ogrn_days_end_month', 'ogrn_days_end_quarter', 'cnt_cred_f_oper_1m', 'cnt_cred_f_oper_3m'], errors='ignore')\n\n    return X","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:23.506083Z","iopub.execute_input":"2023-11-30T13:22:23.506473Z","iopub.status.idle":"2023-11-30T13:22:23.521627Z","shell.execute_reply.started":"2023-11-30T13:22:23.506443Z","shell.execute_reply":"2023-11-30T13:22:23.520453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = clean_data(train_df)\ntrain_df = drop_num_features(train_df)\n\n# Remove cluster of strange people\ntrain_df = train_df[~train_df.index.isin(nan_people.index)]","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:23.523234Z","iopub.execute_input":"2023-11-30T13:22:23.523928Z","iopub.status.idle":"2023-11-30T13:22:24.083678Z","shell.execute_reply.started":"2023-11-30T13:22:23.523894Z","shell.execute_reply":"2023-11-30T13:22:24.082741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Category features","metadata":{}},{"cell_type":"markdown","source":"## NaN check","metadata":{}},{"cell_type":"code","source":"train_df.select_dtypes(include='object').isna().sum() / train_df.shape[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:24.085225Z","iopub.execute_input":"2023-11-30T13:22:24.085905Z","iopub.status.idle":"2023-11-30T13:22:24.302940Z","shell.execute_reply.started":"2023-11-30T13:22:24.085860Z","shell.execute_reply":"2023-11-30T13:22:24.301803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 3 feature which NaN ration is higher highter than ~27%. The possible solutions are similar to NaNs in numeric features. The important thing to keep in mind, that categorical features has NaN encoded as python None (not np.NaN)","metadata":{}},{"cell_type":"markdown","source":"## City and city_type relationship","metadata":{}},{"cell_type":"markdown","source":"In this part we investigate product of 2 categorical features: city and city_type. First assumption was that each city has only one city type. But it isn't true for the majority of data.","metadata":{}},{"cell_type":"code","source":"train_df.groupby('city').city_type.nunique().rename('number_of_city_types').value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:24.304510Z","iopub.execute_input":"2023-11-30T13:22:24.304883Z","iopub.status.idle":"2023-11-30T13:22:24.415573Z","shell.execute_reply.started":"2023-11-30T13:22:24.304852Z","shell.execute_reply":"2023-11-30T13:22:24.414330Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Then we decided to look from the other side - number of unique cities for each city_type.","metadata":{}},{"cell_type":"code","source":"train_df.groupby('city_type').city.nunique().rename('number of unique cities').value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:24.417433Z","iopub.execute_input":"2023-11-30T13:22:24.418288Z","iopub.status.idle":"2023-11-30T13:22:24.526010Z","shell.execute_reply.started":"2023-11-30T13:22:24.418244Z","shell.execute_reply":"2023-11-30T13:22:24.524949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Almost all city types are useless, because have only a few towns. We had a theory that these city types may belong city with over a million people. To check if it's true we can add count for each city_type. We expect that these city types have only a few cities by appear a lot (because it's large towns)","metadata":{}},{"cell_type":"code","source":"city_type_info = train_df.groupby('city_type').agg({'city':['count', 'nunique']})\ncity_type_info.columns = ['count', 'unique_cities']\ncity_type_info.sort_values('count', ascending=False).head(20)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:24.527529Z","iopub.execute_input":"2023-11-30T13:22:24.527940Z","iopub.status.idle":"2023-11-30T13:22:24.660437Z","shell.execute_reply.started":"2023-11-30T13:22:24.527900Z","shell.execute_reply":"2023-11-30T13:22:24.659202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"By these theory crashes, because there are no city_types with large count, but small unique towns counts. Given this table, we can take in account only a few city types like '3597', '1252'. Thus these feature can be easily encoded using One Hot Encoding.","metadata":{}},{"cell_type":"code","source":"def print_type_target(city_type):\n    print(f\"\"\"\n        Mean target of city_type == {city_type} {train_df[train_df['city_type'] == city_type].total_target.mean()}\n        Mean target of city_type != {city_type} {train_df[train_df['city_type'] != city_type].total_target.mean()}\n    \"\"\")","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:24.661902Z","iopub.execute_input":"2023-11-30T13:22:24.662317Z","iopub.status.idle":"2023-11-30T13:22:24.667207Z","shell.execute_reply.started":"2023-11-30T13:22:24.662285Z","shell.execute_reply":"2023-11-30T13:22:24.666403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_type_target('3597')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:24.668254Z","iopub.execute_input":"2023-11-30T13:22:24.668734Z","iopub.status.idle":"2023-11-30T13:22:24.897590Z","shell.execute_reply.started":"2023-11-30T13:22:24.668707Z","shell.execute_reply":"2023-11-30T13:22:24.896514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print_type_target('1252')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:24.900246Z","iopub.execute_input":"2023-11-30T13:22:24.901342Z","iopub.status.idle":"2023-11-30T13:22:25.119851Z","shell.execute_reply.started":"2023-11-30T13:22:24.901240Z","shell.execute_reply":"2023-11-30T13:22:25.118541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Channel code","metadata":{}},{"cell_type":"markdown","source":"This feature has a lot of unique values, which leads to 2 main problems:\n\n- One Hot Encoding representation will be really sparse, with a lot of rare categories.\n- Some of channels might not be present in train, but will be in test.\n\nTo mitigate this issue we could explore only top-k frequent values. We suggest to take all top-15 categories (more than ~1.8% of occurence). The choice of threshold can be system hyperparameter. For less frequent or unknown groups we will create category others. This is important for filter out small groups that are not representative.","metadata":{}},{"cell_type":"code","source":"def plot_top_k_encoding(df, top_k, column_name):\n    \n    df = df.copy()\n    \n    column_counts = df[column_name].value_counts(normalize=True)\n    \n    frequent_values = list(column_counts.iloc[:top_k].index)\n    \n    column = df[column_name]\n    column[~column.isin(frequent_values) & column.notna()] = 'other'\n                            \n    df.loc[:, column_name] = column\n    \n    frequent_values = frequent_values + ['other']\n    \n    column_target = df.groupby(column_name).total_target.mean()\n    \n    sns.barplot(x=column_target.index, y=column_target, order=frequent_values)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:25.121674Z","iopub.execute_input":"2023-11-30T13:22:25.122237Z","iopub.status.idle":"2023-11-30T13:22:25.128682Z","shell.execute_reply.started":"2023-11-30T13:22:25.122203Z","shell.execute_reply":"2023-11-30T13:22:25.127313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"channel_top_k = 15","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:25.129993Z","iopub.execute_input":"2023-11-30T13:22:25.130346Z","iopub.status.idle":"2023-11-30T13:22:25.146244Z","shell.execute_reply.started":"2023-11-30T13:22:25.130316Z","shell.execute_reply":"2023-11-30T13:22:25.144751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_top_k_encoding(train_df, channel_top_k, 'channel_code')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:25.148057Z","iopub.execute_input":"2023-11-30T13:22:25.148598Z","iopub.status.idle":"2023-11-30T13:22:25.968868Z","shell.execute_reply.started":"2023-11-30T13:22:25.148559Z","shell.execute_reply":"2023-11-30T13:22:25.967695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The channel codes are ordered by their frequency with other channels at the end. There is no clear relationship between frequency and target variable, so frequency encoding might be a ba choice, target and one hot encodings might be more suitable.","metadata":{}},{"cell_type":"markdown","source":"## Relevance of ogrn_month and ogrn_year","metadata":{}},{"cell_type":"markdown","source":"Both variable will be encoded using ordinal encoding\n\nThe common sense gives us a hint that periodic feature wouldn't influence the target variable. It doesn't tell us anything about the company and possible bring noise to data. On the other hand ogrn_year could tell us about its experience.","metadata":{}},{"cell_type":"code","source":"train_df['ogrn_month'] = pd.to_numeric(train_df['ogrn_month'])\ntrain_df['ogrn_year'] = pd.to_numeric(train_df['ogrn_year'])","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:25.970291Z","iopub.execute_input":"2023-11-30T13:22:25.970736Z","iopub.status.idle":"2023-11-30T13:22:26.357687Z","shell.execute_reply.started":"2023-11-30T13:22:25.970705Z","shell.execute_reply":"2023-11-30T13:22:26.356438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['total_target']","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:26.359093Z","iopub.execute_input":"2023-11-30T13:22:26.359683Z","iopub.status.idle":"2023-11-30T13:22:26.368628Z","shell.execute_reply.started":"2023-11-30T13:22:26.359651Z","shell.execute_reply":"2023-11-30T13:22:26.367449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.loc[train_df.total_target == 1, 'ogrn_month']","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:26.369975Z","iopub.execute_input":"2023-11-30T13:22:26.370406Z","iopub.status.idle":"2023-11-30T13:22:26.386071Z","shell.execute_reply.started":"2023-11-30T13:22:26.370372Z","shell.execute_reply":"2023-11-30T13:22:26.384873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axarr = plt.subplots(figsize=(8, 4))\n\nsns.histplot(x=train_df.loc[train_df.total_target == 1, 'ogrn_month'], stat='probability', binwidth=1)\nsns.histplot(x=train_df.loc[train_df.total_target == 0, 'ogrn_month'], stat='probability', binwidth=1)\nplt.title('ogrn_month disctribution for both target values')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:26.387509Z","iopub.execute_input":"2023-11-30T13:22:26.388572Z","iopub.status.idle":"2023-11-30T13:22:26.932947Z","shell.execute_reply.started":"2023-11-30T13:22:26.388537Z","shell.execute_reply":"2023-11-30T13:22:26.931677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The distributions don't differ too much, that's  a bad discriminative feature as we suggested.","metadata":{}},{"cell_type":"code","source":"sns.boxplot(data=train_df, y='ogrn_year', x='total_target')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:26.934679Z","iopub.execute_input":"2023-11-30T13:22:26.935493Z","iopub.status.idle":"2023-11-30T13:22:27.215928Z","shell.execute_reply.started":"2023-11-30T13:22:26.935459Z","shell.execute_reply":"2023-11-30T13:22:27.214636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Newer companies (that register closer to 2020) are more likely to come from churn distribution.","metadata":{}},{"cell_type":"markdown","source":"## City and index_city_code","metadata":{}},{"cell_type":"markdown","source":"At first glance, both city and index_city_code contains the same information about the location. We decided to check if each city has one and only one index_city_code and vise versa (which makes sense).","metadata":{}},{"cell_type":"code","source":"train_df.groupby('city').index_city_code.nunique().rename('unique index codes').value_counts()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:27.217914Z","iopub.execute_input":"2023-11-30T13:22:27.218358Z","iopub.status.idle":"2023-11-30T13:22:27.338402Z","shell.execute_reply.started":"2023-11-30T13:22:27.218319Z","shell.execute_reply":"2023-11-30T13:22:27.337286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.groupby('index_city_code').city.nunique().rename('unique cities').value_counts().head(10)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:27.339763Z","iopub.execute_input":"2023-11-30T13:22:27.340201Z","iopub.status.idle":"2023-11-30T13:22:27.452228Z","shell.execute_reply.started":"2023-11-30T13:22:27.340161Z","shell.execute_reply":"2023-11-30T13:22:27.450974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, the relationship is very inconsistent - in addition to this index has a ~66% of NaN values. Our team decided to drop that suspicious feature.","metadata":{}},{"cell_type":"markdown","source":"## okved","metadata":{}},{"cell_type":"markdown","source":"Here we apply the same strategy as with channel codes.","metadata":{}},{"cell_type":"code","source":"okved_top_n = 20","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:27.453545Z","iopub.execute_input":"2023-11-30T13:22:27.454595Z","iopub.status.idle":"2023-11-30T13:22:27.458990Z","shell.execute_reply.started":"2023-11-30T13:22:27.454561Z","shell.execute_reply":"2023-11-30T13:22:27.458199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_top_k_encoding(train_df, okved_top_n, 'okved')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:27.460704Z","iopub.execute_input":"2023-11-30T13:22:27.461680Z","iopub.status.idle":"2023-11-30T13:22:28.246338Z","shell.execute_reply.started":"2023-11-30T13:22:27.461635Z","shell.execute_reply":"2023-11-30T13:22:28.245083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In addition to no frequency relationship, the discriminative power of this feature is weaker (the difference between different bars' heights). We will try both target and one hot encoding in modeling part.","metadata":{}},{"cell_type":"markdown","source":"## Segment","metadata":{}},{"cell_type":"markdown","source":"That feature is much more simpler, because it has only 4 unique values. One Hot Encoding will be sifficient.","metadata":{}},{"cell_type":"code","source":"segment_target = train_df.groupby('segment').total_target.mean()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:28.250640Z","iopub.execute_input":"2023-11-30T13:22:28.250986Z","iopub.status.idle":"2023-11-30T13:22:28.288525Z","shell.execute_reply.started":"2023-11-30T13:22:28.250949Z","shell.execute_reply":"2023-11-30T13:22:28.287648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.barplot(x=segment_target.index, y=segment_target)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:28.289773Z","iopub.execute_input":"2023-11-30T13:22:28.290392Z","iopub.status.idle":"2023-11-30T13:22:28.521444Z","shell.execute_reply.started":"2023-11-30T13:22:28.290353Z","shell.execute_reply":"2023-11-30T13:22:28.519967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"One segment is very likely to leave the bank. We could check total sum of payments for different periods to assume what type of people they are. That will in a different section for business insights.","metadata":{}},{"cell_type":"markdown","source":"## Branch Code and City","metadata":{}},{"cell_type":"markdown","source":"In opinion of our team these 2 variables carry only geo and historical information (if the the departament was doing bad or good for a long time) and can't carry high-level information about pattern. In addition to it these features has high cardinality, that assumes usage of target encoding.","metadata":{}},{"cell_type":"markdown","source":"# Final categorical feature code","metadata":{}},{"cell_type":"code","source":"def drop_cat_features(df):\n    \n    return df.drop(columns=['index_city_code', 'ogrn_month', 'city', 'branch_code'], errors='ignore')","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:28.522865Z","iopub.execute_input":"2023-11-30T13:22:28.523319Z","iopub.status.idle":"2023-11-30T13:22:28.529487Z","shell.execute_reply.started":"2023-11-30T13:22:28.523281Z","shell.execute_reply":"2023-11-30T13:22:28.528234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = drop_cat_features(train_df)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:28.531082Z","iopub.execute_input":"2023-11-30T13:22:28.531444Z","iopub.status.idle":"2023-11-30T13:22:28.633584Z","shell.execute_reply.started":"2023-11-30T13:22:28.531416Z","shell.execute_reply":"2023-11-30T13:22:28.632505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"code","source":"def get_sum_of_paym_ratio_features(df):\n    \n    sum_of_paym_12_6 = df['sum_of_paym_1y'] - df['sum_of_paym_6m']\n    sum_of_paym_6_2 = df['sum_of_paym_6m'] - df['sum_of_paym_2m']\n    \n    df['sum_of_paym_ratio_1'] = sum_of_paym_12_6/sum_of_paym_6_2\n    df['sum_of_paym_ratio_2'] = sum_of_paym_6_2/df['sum_of_paym_2m']\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:28.634704Z","iopub.execute_input":"2023-11-30T13:22:28.634995Z","iopub.status.idle":"2023-11-30T13:22:28.641462Z","shell.execute_reply.started":"2023-11-30T13:22:28.634970Z","shell.execute_reply":"2023-11-30T13:22:28.640207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"unilateral_oper = ['a', 'b', 'c']\nbilateral_oper = ['d', 'e', 'f', 'g', 'h']\n\nperiods = ['1m', '3m']\n\ndef get_deb_cred_ratio_features(df):\n    \n    for oper in bilateral_oper:\n        for period in periods:\n            df[f'deb_cred_{oper}_{period}_ratio'] = df[f'sum_cred_{oper}_oper_{period}'] / df[f'sum_deb_{oper}_oper_{period}']\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:28.642826Z","iopub.execute_input":"2023-11-30T13:22:28.643404Z","iopub.status.idle":"2023-11-30T13:22:28.658349Z","shell.execute_reply.started":"2023-11-30T13:22:28.643373Z","shell.execute_reply":"2023-11-30T13:22:28.657174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_features(df):\n    \n    df = get_sum_of_paym_ratio_features(df)\n    df = get_deb_cred_ratio_features(df)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:28.659961Z","iopub.execute_input":"2023-11-30T13:22:28.660622Z","iopub.status.idle":"2023-11-30T13:22:28.668138Z","shell.execute_reply.started":"2023-11-30T13:22:28.660583Z","shell.execute_reply":"2023-11-30T13:22:28.667223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = get_features(train_df)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:28.669420Z","iopub.execute_input":"2023-11-30T13:22:28.669704Z","iopub.status.idle":"2023-11-30T13:22:28.706336Z","shell.execute_reply.started":"2023-11-30T13:22:28.669681Z","shell.execute_reply":"2023-11-30T13:22:28.704665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Target Distibution","metadata":{}},{"cell_type":"markdown","source":"Using balanced weights for each class might be an appropriate desicion","metadata":{}},{"cell_type":"code","source":"train_df['total_target'].mean()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:28.708102Z","iopub.execute_input":"2023-11-30T13:22:28.708540Z","iopub.status.idle":"2023-11-30T13:22:28.718567Z","shell.execute_reply.started":"2023-11-30T13:22:28.708508Z","shell.execute_reply":"2023-11-30T13:22:28.716860Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As for additional targets (total_target = max(target_1, target_2)), their estimation would be a multilabel task. Given the prediction, we could aggregate them (mean, weighted mean, stacking) to get the final answer. We believe that more complex approach for predicting total target can give better results. ","metadata":{}},{"cell_type":"code","source":"train_df.groupby(['target_1', 'target_2']).size()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:28.720082Z","iopub.execute_input":"2023-11-30T13:22:28.720525Z","iopub.status.idle":"2023-11-30T13:22:28.750581Z","shell.execute_reply.started":"2023-11-30T13:22:28.720484Z","shell.execute_reply":"2023-11-30T13:22:28.749373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Holdout Split","metadata":{}},{"cell_type":"markdown","source":"The holdout part will be useful for\n\n- Performing feature improtance calculation (based on permutation importance and SHAP values that are useful for non-interpretable models)\n- Evaluation our model perfomance using different metrics\n- Stacking our model for final submission\n\nThe size was chosen to be the same as public and private leaderboard (50000 samples), stratified option is used.\n\nSmall portion of data will be used for independent analisys of relevant uncorrelated features. Using seperate data part for feature removal will give us unbiased estimates of model perfomance, because election and training will be 2 seperate processes. In addition to this, we can calculate all statistics for target encoding for categorical features without any data leakage.","metadata":{}},{"cell_type":"code","source":"df, df_holdout = train_test_split(train_df, test_size=50000, stratify=train_df['total_target'], random_state=42)\n# df, select_df = train_test_split(df, test_size=50000, stratify=df['total_target'], random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:28.752343Z","iopub.execute_input":"2023-11-30T13:22:28.752765Z","iopub.status.idle":"2023-11-30T13:22:29.297402Z","shell.execute_reply.started":"2023-11-30T13:22:28.752728Z","shell.execute_reply":"2023-11-30T13:22:29.296223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop(columns=['total_target','target_1', 'target_2'])\ny = df['total_target']\ny_multi = df[['target_1', 'target_2', 'total_target']]","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:29.298630Z","iopub.execute_input":"2023-11-30T13:22:29.298941Z","iopub.status.idle":"2023-11-30T13:22:29.423506Z","shell.execute_reply.started":"2023-11-30T13:22:29.298915Z","shell.execute_reply":"2023-11-30T13:22:29.422352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# select_X = select_df.drop(columns=['total_target', 'target_1', 'target_2'])\n# select_y = select_df['total_target']","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:29.424970Z","iopub.execute_input":"2023-11-30T13:22:29.425297Z","iopub.status.idle":"2023-11-30T13:22:29.431325Z","shell.execute_reply.started":"2023-11-30T13:22:29.425271Z","shell.execute_reply":"2023-11-30T13:22:29.429296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Competitive Models ","metadata":{}},{"cell_type":"markdown","source":"## KFold and submit functions","metadata":{}},{"cell_type":"markdown","source":"Model tuning will be performed using optuna with objective function being RepeatedStratifiedKFold evaluation.","metadata":{}},{"cell_type":"code","source":"def submit(model, title):\n    df_test = pd.read_parquet('/kaggle/input/alpha-contest/test.parquet')\n    \n    df_test = drop_num_features(df_test)\n    df_test = drop_cat_features(df_test)\n    \n    df_test = get_features(df_test)\n    \n    X_test = df_test.drop(columns='id')\n    \n    y_pred = model.predict_proba(X_test)[:, 1]\n    \n    sub = pd.concat([df_test['id'], pd.Series(y_pred)], axis=1)\n    sub.columns = ['id', 'score']\n    sub.to_csv(f'submission_{title}.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:29.432580Z","iopub.execute_input":"2023-11-30T13:22:29.432915Z","iopub.status.idle":"2023-11-30T13:22:29.446991Z","shell.execute_reply.started":"2023-11-30T13:22:29.432855Z","shell.execute_reply":"2023-11-30T13:22:29.445686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reproducibility\nnp.random.seed(42)\n\nn_repeats = 3\nn_splits = 5\n\nkf = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:29.448445Z","iopub.execute_input":"2023-11-30T13:22:29.449390Z","iopub.status.idle":"2023-11-30T13:22:29.457772Z","shell.execute_reply.started":"2023-11-30T13:22:29.449357Z","shell.execute_reply":"2023-11-30T13:22:29.456784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_kfold(model, X, y):\n    auc_scores = []\n\n    for i, (train_idx, valid_idx) in tqdm(enumerate(kf.split(X, y)), total=n_splits*n_repeats):\n\n        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n        X_valid, y_valid = X.iloc[valid_idx], y.iloc[valid_idx]\n\n        model.fit(X_train, y_train)\n\n        y_pred = model.predict_proba(X_valid)[:, 1]\n\n        auc_scores.append(roc_auc_score(y_valid, y_pred))\n\n    auc_scores = pd.Series(auc_scores, name='auc_scores')\n    \n    return auc_scores","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:29.459175Z","iopub.execute_input":"2023-11-30T13:22:29.459491Z","iopub.status.idle":"2023-11-30T13:22:29.473022Z","shell.execute_reply.started":"2023-11-30T13:22:29.459466Z","shell.execute_reply":"2023-11-30T13:22:29.471960Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_multi_kfold(model, X, y):\n    auc_scores = []\n\n    for i, (train_idx, valid_idx) in tqdm(enumerate(kf.split(X, y.iloc[:, 2])), total=n_splits*n_repeats):\n\n        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n        X_valid, y_valid = X.iloc[valid_idx], y.iloc[valid_idx]\n\n        model.fit(X_train, y_train)\n\n        y_pred = model.predict_proba(X_valid)\n\n        auc_scores.append(roc_auc_score(y_valid.iloc[:, 2], y_pred))\n\n    auc_scores = pd.Series(auc_scores, name='auc_scores')\n    \n    return auc_scores","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:29.474426Z","iopub.execute_input":"2023-11-30T13:22:29.474802Z","iopub.status.idle":"2023-11-30T13:22:29.485559Z","shell.execute_reply.started":"2023-11-30T13:22:29.474771Z","shell.execute_reply":"2023-11-30T13:22:29.484367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_auc_scores(auc_scores):\n    sns.boxplot(auc_scores)\n    plt.title(f'Mean: {np.mean(auc_scores):.6f}, Std: {np.std(auc_scores):.6f}')\n    sns.despine(right=True, top=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:29.486828Z","iopub.execute_input":"2023-11-30T13:22:29.487212Z","iopub.status.idle":"2023-11-30T13:22:29.495808Z","shell.execute_reply.started":"2023-11-30T13:22:29.487177Z","shell.execute_reply":"2023-11-30T13:22:29.494662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cv_and_lb(model, X, y, title, eval_func):\n    model_auc_scores = eval_func(model, X, y)\n    plot_auc_scores(model_auc_scores)\n    model.fit(X, y)\n    submit(model, title)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:29.497364Z","iopub.execute_input":"2023-11-30T13:22:29.498041Z","iopub.status.idle":"2023-11-30T13:22:29.508324Z","shell.execute_reply.started":"2023-11-30T13:22:29.498007Z","shell.execute_reply":"2023-11-30T13:22:29.507342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## LightGBM total target pipeline","metadata":{}},{"cell_type":"markdown","source":"Key points of that pipeline:\n\n- Using only total_target as a label\n- 2 seperate pipelines for numerical and categorical features\n- Simple Imputation Technique (Median, Most frequent)\n- All categorical features are encoded with one hot encoding (top-k values are taken into account)","metadata":{}},{"cell_type":"code","source":"# This transformer takes ONE categorical feature\n# Takes only TopK values (other converted to other)\n# And perform one hot encoding\nclass OheTopK(TransformerMixin, BaseEstimator):\n    \n    def __init__(self, top_k, include_other=True):\n        self.top_k = top_k\n        self.include_other = include_other\n       \n    \n    def fit(self, X, y=None):\n        \n        # X is a one column to perform OheTopK, that is a numpy array\n        X = pd.Series(np.squeeze(X.copy()))\n        self.frequent_values = list(X.value_counts().head(self.top_k).index)\n        \n        X[~X.isin(self.frequent_values)] = 'other'\n        \n        self.ohe = OneHotEncoder(categories = [self.frequent_values + (['other'] if self.include_other else [])], \n                                 handle_unknown='ignore')\n        \n        self.ohe = self.ohe.fit(X.values.reshape(-1, 1))\n        \n        return self\n    \n    def transform(self, X, y=None):\n        \n        X = pd.Series(np.squeeze(X.copy()))\n        X[~X.isin(self.frequent_values)] = 'other'\n        \n        X = self.ohe.transform(X.values.reshape(-1, 1))\n        \n        return X","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:29.509451Z","iopub.execute_input":"2023-11-30T13:22:29.510428Z","iopub.status.idle":"2023-11-30T13:22:29.521214Z","shell.execute_reply.started":"2023-11-30T13:22:29.510385Z","shell.execute_reply":"2023-11-30T13:22:29.520252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_imputer = SimpleImputer(strategy='median')\n\nnum_pipeline = make_pipeline(num_imputer)\n\ncat_imputer = SimpleImputer(strategy='most_frequent', missing_values=None)\ncat_encoder = make_column_transformer(\n    (OheTopK(15), [0]),\n    (OheTopK(2), [1]),\n    (OheTopK(20), [2]),\n    (OneHotEncoder(categories=[['0', '1', '2', '3']], handle_unknown='ignore'), [3]),\n)\ncat_pipeline = make_pipeline(cat_imputer, cat_encoder)\n\nfeature_preprocessing = make_column_transformer(\n    (num_pipeline, make_column_selector(dtype_include='number')),\n    (cat_pipeline, make_column_selector(dtype_include='object'))\n)\n\nlgbm1_model = make_pipeline(\n    feature_preprocessing,\n    LGBMClassifier(n_estimators=100, class_weight='balanced')\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:29.522485Z","iopub.execute_input":"2023-11-30T13:22:29.523708Z","iopub.status.idle":"2023-11-30T13:22:29.539090Z","shell.execute_reply.started":"2023-11-30T13:22:29.523675Z","shell.execute_reply":"2023-11-30T13:22:29.538211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cv_and_lb(lgbm1_model, X, y, 'lgbm1', get_kfold)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:29.540540Z","iopub.execute_input":"2023-11-30T13:22:29.540941Z","iopub.status.idle":"2023-11-30T13:22:29.550471Z","shell.execute_reply.started":"2023-11-30T13:22:29.540905Z","shell.execute_reply":"2023-11-30T13:22:29.549425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LGBM multilabel targets","metadata":{}},{"cell_type":"code","source":"class MultiLabelClassificator(BaseEstimator):\n    \n    def __init__(self, base_estimator, agg_func):\n        self.base_estimator = base_estimator\n        self.agg_func = agg_func\n        \n    def fit(self, X, y):\n        self.estimators = [\n            self.base_estimator.fit(X, y.iloc[:, 0]),\n            self.base_estimator.fit(X, y.iloc[:, 1])\n        ]\n        \n        return self\n    \n    def predict_proba(self, X):\n        predicts = [\n            self.estimators[0].predict_proba(X)[:, 1],\n            self.estimators[1].predict_proba(X)[:, 1]\n        ]\n        \n        return self.agg_func(predicts)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:29.552002Z","iopub.execute_input":"2023-11-30T13:22:29.552859Z","iopub.status.idle":"2023-11-30T13:22:29.562445Z","shell.execute_reply.started":"2023-11-30T13:22:29.552694Z","shell.execute_reply":"2023-11-30T13:22:29.561553Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_imputer = SimpleImputer(strategy='median')\n\nnum_pipeline = make_pipeline(num_imputer)\n\ncat_imputer = SimpleImputer(strategy='most_frequent', missing_values=None)\ncat_encoder = make_column_transformer(\n    (OheTopK(15), [0]),\n    (OheTopK(2), [1]),\n    (OheTopK(20), [2]),\n    (OneHotEncoder(categories=[['0', '1', '2', '3']], handle_unknown='ignore'), [3]),\n)\ncat_pipeline = make_pipeline(cat_imputer, cat_encoder)\n\nfeature_preprocessing = make_column_transformer(\n    (num_pipeline, make_column_selector(dtype_include='number')),\n    (cat_pipeline, make_column_selector(dtype_include='object'))\n)\n\nlgbm2_model = make_pipeline(\n    feature_preprocessing,\n    MultiLabelClassificator(LGBMClassifier(), lambda preds :(preds[0] + preds[1])/2)\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:29.563873Z","iopub.execute_input":"2023-11-30T13:22:29.564560Z","iopub.status.idle":"2023-11-30T13:22:29.579161Z","shell.execute_reply.started":"2023-11-30T13:22:29.564520Z","shell.execute_reply":"2023-11-30T13:22:29.577933Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cv_and_lb(lgbm2_model, X, y_multi, 'lgbm2', get_multi_kfold)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:22:29.580641Z","iopub.execute_input":"2023-11-30T13:22:29.581549Z","iopub.status.idle":"2023-11-30T13:22:29.590158Z","shell.execute_reply.started":"2023-11-30T13:22:29.581510Z","shell.execute_reply":"2023-11-30T13:22:29.588717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Interpretable model","metadata":{}},{"cell_type":"markdown","source":"## Feature correlation","metadata":{}},{"cell_type":"markdown","source":"Multicollinear features is a problem, because interpretation of our features becomes hard (feature importance is spread across correlated features).\n\nTo deals with it we iterate over features and all the features that correlate with current more than a given threshold. The suggsted threshold is 0.5 - strong correlation","metadata":{}},{"cell_type":"code","source":"CORR_THRESHOLD = 0.5","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:23:38.723891Z","iopub.execute_input":"2023-11-30T13:23:38.724298Z","iopub.status.idle":"2023-11-30T13:23:38.729521Z","shell.execute_reply.started":"2023-11-30T13:23:38.724266Z","shell.execute_reply":"2023-11-30T13:23:38.728236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# takes some time\nX_num = X.select_dtypes(include='number')\ncorr = X_num.corr(method='pearson').abs()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:23:38.869921Z","iopub.execute_input":"2023-11-30T13:23:38.870340Z","iopub.status.idle":"2023-11-30T13:23:45.861820Z","shell.execute_reply.started":"2023-11-30T13:23:38.870309Z","shell.execute_reply":"2023-11-30T13:23:45.860985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr.style.background_gradient()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:23:45.863406Z","iopub.execute_input":"2023-11-30T13:23:45.863905Z","iopub.status.idle":"2023-11-30T13:23:46.384868Z","shell.execute_reply.started":"2023-11-30T13:23:45.863876Z","shell.execute_reply":"2023-11-30T13:23:46.383839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look at the most correlating pairs!","metadata":{}},{"cell_type":"code","source":"corr_pairs = []\n\nfor i in range(0, corr.shape[0]):\n    for j in range(i+1, corr.shape[0]):\n        \n        if corr.iloc[i, j] > CORR_THRESHOLD:\n            corr_pairs.append((X_num.columns[i], X_num.columns[j], corr.iloc[i, j]))\n\ncorr_pairs.sort(key = lambda t : t[2], reverse=True)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:23:46.386371Z","iopub.execute_input":"2023-11-30T13:23:46.387071Z","iopub.status.idle":"2023-11-30T13:23:46.499330Z","shell.execute_reply.started":"2023-11-30T13:23:46.387032Z","shell.execute_reply":"2023-11-30T13:23:46.498351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N = len(corr_pairs[:10])\nfig, axarr = plt.subplots(nrows=N, figsize=(10, 6*N))\n\nfor i in range(N):\n    pair = corr_pairs[i]\n    cur_ax = axarr[i]\n    sns.scatterplot(x=X_num[pair[0]], y=X_num[pair[1]], ax=cur_ax)\n    cur_ax.set_title(pair[2])","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:23:46.501507Z","iopub.execute_input":"2023-11-30T13:23:46.501857Z","iopub.status.idle":"2023-11-30T13:24:01.197417Z","shell.execute_reply.started":"2023-11-30T13:23:46.501827Z","shell.execute_reply":"2023-11-30T13:24:01.196212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_table = corr.unstack().drop_duplicates().reset_index()\ncorr_table.columns = ['feature_1', 'feature_2', 'corr']\ncorr_table = corr_table[corr_table['feature_1'] != corr_table['feature_2']]\ncorr_table = corr_table[corr_table['corr'] > CORR_THRESHOLD]","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:24:01.198845Z","iopub.execute_input":"2023-11-30T13:24:01.199658Z","iopub.status.idle":"2023-11-30T13:24:01.211195Z","shell.execute_reply.started":"2023-11-30T13:24:01.199625Z","shell.execute_reply":"2023-11-30T13:24:01.210124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr_rel = defaultdict(list)\n\nfor i in range(corr_table.shape[0]):\n\n    corr_rel[corr_table.iloc[i, 0]].append(corr_table.iloc[i, 1])\n    corr_rel[corr_table.iloc[i, 1]].append(corr_table.iloc[i, 0])","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:24:01.212572Z","iopub.execute_input":"2023-11-30T13:24:01.212933Z","iopub.status.idle":"2023-11-30T13:24:01.236249Z","shell.execute_reply.started":"2023-11-30T13:24:01.212871Z","shell.execute_reply":"2023-11-30T13:24:01.235188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_num_features = []\nbanned_features = set()\n\nfor feature in X_num.columns:\n    \n    if feature not in banned_features:\n        selected_num_features.append(feature)\n        \n        for to_ban in corr_rel[feature]:\n            banned_features.add(to_ban)\n        \nprint(f\"\"\"\n      {X_num.shape[1]} num features before correlation removal\n      {len(selected_num_features)} num features after correlation removal\n\"\"\")","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:24:01.237538Z","iopub.execute_input":"2023-11-30T13:24:01.238303Z","iopub.status.idle":"2023-11-30T13:24:01.244399Z","shell.execute_reply.started":"2023-11-30T13:24:01.238271Z","shell.execute_reply":"2023-11-30T13:24:01.243477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_features = selected_num_features + list(X.select_dtypes(include='object').columns)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:24:01.245665Z","iopub.execute_input":"2023-11-30T13:24:01.246414Z","iopub.status.idle":"2023-11-30T13:24:01.287619Z","shell.execute_reply.started":"2023-11-30T13:24:01.246357Z","shell.execute_reply":"2023-11-30T13:24:01.286245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_corr = X_num[selected_num_features].corr().abs()\nfiltered_corr.style.background_gradient()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:24:01.289569Z","iopub.execute_input":"2023-11-30T13:24:01.290010Z","iopub.status.idle":"2023-11-30T13:24:02.464936Z","shell.execute_reply.started":"2023-11-30T13:24:01.289969Z","shell.execute_reply":"2023-11-30T13:24:02.463909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_interpretable = X[selected_features]\nX_interpretable.shape","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:25:14.025236Z","iopub.execute_input":"2023-11-30T13:25:14.025625Z","iopub.status.idle":"2023-11-30T13:25:14.068651Z","shell.execute_reply.started":"2023-11-30T13:25:14.025596Z","shell.execute_reply":"2023-11-30T13:25:14.067282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model? Logistic Regression!","metadata":{}},{"cell_type":"markdown","source":"The first algorithm that comes to mind in terms of interpretability is a logistic regression! Model weights can show the importance of each feature and its impact on final prediction!\n\nOur pipepline consists of several key points:\n\n- Logistic Regression requires proper choice of standardization method and optimization solver. For our task the best choice, that would converge in a given number of iters was (Standard Scaler + newton-cholesky solver)\n- Median and most-frequent imputations were used for numeric and categorical features accordingly.\n- OneHotEncoding for categorical features drop the first category to avoid collinearity.","metadata":{}},{"cell_type":"code","source":"num_imputer = SimpleImputer(strategy='median')\nscaler = StandardScaler()\nnum_pipeline = make_pipeline(num_imputer, StandardScaler)\n\ncat_imputer = SimpleImputer(strategy='most_frequent', missing_values=None)\ncat_encoder = make_column_transformer(\n    (OheTopK(15, False), [0]),\n    (OheTopK(2, False), [1]),\n    (OheTopK(20, False), [2]),\n    (OneHotEncoder(categories=[['0', '1', '2', '3']], handle_unknown='ignore', drop='first'), [3]),\n)\ncat_pipeline = make_pipeline(cat_imputer, cat_encoder)\n\nfeature_preprocessing = make_column_transformer(\n    (num_imputer, make_column_selector(dtype_include='number')),\n    (cat_pipeline, make_column_selector(dtype_include='object'))\n)\n\nlr_model = make_pipeline(\n    feature_preprocessing,\n    LogisticRegression(solver='newton-cholesky')\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:54:13.366320Z","iopub.execute_input":"2023-11-30T13:54:13.366725Z","iopub.status.idle":"2023-11-30T13:54:13.374977Z","shell.execute_reply.started":"2023-11-30T13:54:13.366692Z","shell.execute_reply":"2023-11-30T13:54:13.373827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = feature_preprocessing.fit_transform(X_interpretable, y)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T13:54:13.598020Z","iopub.execute_input":"2023-11-30T13:54:13.598423Z","iopub.status.idle":"2023-11-30T13:54:17.029638Z","shell.execute_reply.started":"2023-11-30T13:54:13.598391Z","shell.execute_reply":"2023-11-30T13:54:17.028538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv_and_lb(lr_model, X_interpretable, y, 'tt', get_kfold)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T14:00:12.577104Z","iopub.execute_input":"2023-11-30T14:00:12.577511Z","iopub.status.idle":"2023-11-30T14:00:33.731851Z","shell.execute_reply.started":"2023-11-30T14:00:12.577480Z","shell.execute_reply":"2023-11-30T14:00:33.729903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Holdout Feature Importance (permutation + SHAP values)","metadata":{}},{"cell_type":"markdown","source":"# Holdout Metrics (interpretable vs main models vs seper targets)","metadata":{}},{"cell_type":"markdown","source":"## Holdout Stacking + Submission","metadata":{}},{"cell_type":"code","source":"def submit(model):\n    df_test = pd.read_parquet('/kaggle/input/alpha-contest/test.parquet')\n    \n    df_test = drop_num_features(df_test)\n    df_test = drop_cat_features(df_test)\n    \n    df_test = get_features(df_test)\n    \n    X_test = df_test.drop(columns='id')\n    \n    y_pred = model.predict_proba(X_test)[:, 1]\n    \n    sub = pd.concat([df_test['id'], pd.Series(y_pred)], axis=1)\n    sub.columns = ['id', 'score']\n    sub.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T10:59:21.906210Z","iopub.status.idle":"2023-11-29T10:59:21.906771Z","shell.execute_reply.started":"2023-11-29T10:59:21.906492Z","shell.execute_reply":"2023-11-29T10:59:21.906520Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Semi-supervised Approach","metadata":{}},{"cell_type":"code","source":"num_imputer = SimpleImputer(strategy='median')\n\nnum_pipeline = make_pipeline(num_imputer)\n\ncat_imputer = SimpleImputer(strategy='most_frequent', missing_values=None)\ncat_encoder = make_column_transformer(\n    (OheTopK(15), [0]),\n    (OheTopK(2), [1]),\n    (OheTopK(20), [2]),\n    (OneHotEncoder(categories=[['0', '1', '2', '3']], handle_unknown='ignore'), [3]),\n)\ncat_pipeline = make_pipeline(cat_imputer, cat_encoder)\n\nfeature_preprocessing = make_column_transformer(\n    (num_pipeline, make_column_selector(dtype_include='number')),\n    (cat_pipeline, make_column_selector(dtype_include='object'))\n)\n\nmodel = make_pipeline(\n    feature_preprocessing,\n    CatBoostClassifier(n_estimators=100, verbose=0, task_type=\"GPU\", devices='0:1')\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T13:01:20.964833Z","iopub.execute_input":"2023-11-29T13:01:20.965529Z","iopub.status.idle":"2023-11-29T13:01:20.972710Z","shell.execute_reply.started":"2023-11-29T13:01:20.965485Z","shell.execute_reply":"2023-11-29T13:01:20.971771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X, y)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T13:01:23.144680Z","iopub.execute_input":"2023-11-29T13:01:23.145069Z","iopub.status.idle":"2023-11-29T13:01:53.722204Z","shell.execute_reply.started":"2023-11-29T13:01:23.145035Z","shell.execute_reply":"2023-11-29T13:01:53.721339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_parquet('/kaggle/input/alpha-contest/test.parquet').set_index('id')","metadata":{"execution":{"iopub.status.busy":"2023-11-29T13:01:53.726887Z","iopub.execute_input":"2023-11-29T13:01:53.727744Z","iopub.status.idle":"2023-11-29T13:01:54.381658Z","shell.execute_reply.started":"2023-11-29T13:01:53.727704Z","shell.execute_reply":"2023-11-29T13:01:54.380594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = drop_num_features(test_df)\ntest_df = drop_cat_features(test_df)\ntest_df = get_features(test_df)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T13:01:54.383525Z","iopub.execute_input":"2023-11-29T13:01:54.384266Z","iopub.status.idle":"2023-11-29T13:01:54.473541Z","shell.execute_reply.started":"2023-11-29T13:01:54.384225Z","shell.execute_reply":"2023-11-29T13:01:54.472680Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict_proba(test_df)[:, 1]","metadata":{"execution":{"iopub.status.busy":"2023-11-29T13:02:16.830126Z","iopub.execute_input":"2023-11-29T13:02:16.830656Z","iopub.status.idle":"2023-11-29T13:02:25.901230Z","shell.execute_reply.started":"2023-11-29T13:02:16.830621Z","shell.execute_reply":"2023-11-29T13:02:25.899173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T13:02:25.903000Z","iopub.execute_input":"2023-11-29T13:02:25.903406Z","iopub.status.idle":"2023-11-29T13:02:27.113663Z","shell.execute_reply.started":"2023-11-29T13:02:25.903365Z","shell.execute_reply":"2023-11-29T13:02:27.112559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.concat([df_train_pd.Series(y_pred, test_df.id)]","metadata":{"execution":{"iopub.status.busy":"2023-11-29T12:48:56.393361Z","iopub.execute_input":"2023-11-29T12:48:56.393896Z","iopub.status.idle":"2023-11-29T12:48:56.398901Z","shell.execute_reply.started":"2023-11-29T12:48:56.393867Z","shell.execute_reply":"2023-11-29T12:48:56.397897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(y_pred < 0.15).sum()","metadata":{"execution":{"iopub.status.busy":"2023-11-29T12:14:35.609980Z","iopub.execute_input":"2023-11-29T12:14:35.610417Z","iopub.status.idle":"2023-11-29T12:14:35.618075Z","shell.execute_reply.started":"2023-11-29T12:14:35.610382Z","shell.execute_reply":"2023-11-29T12:14:35.616818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.histplot(y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-11-29T12:13:49.941853Z","iopub.execute_input":"2023-11-29T12:13:49.942325Z","iopub.status.idle":"2023-11-29T12:13:50.491621Z","shell.execute_reply.started":"2023-11-29T12:13:49.942276Z","shell.execute_reply":"2023-11-29T12:13:50.490513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}